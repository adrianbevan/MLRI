{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from __future__ import absolute_import,division,print_function,unicode_literals\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_File( Training_filename , TestData_filename ):\n",
    "    df = pd.read_csv(Training_filename)\n",
    "    df_test = pd.read_csv(TestData_filename)\n",
    "\n",
    "\n",
    "    hidden=df_test\n",
    "\n",
    "    Isotope_List = list(df.pop('Isotope'))\n",
    "    df_test.pop('Isotope')\n",
    "\n",
    "\n",
    "    return df , df_test , Isotope_List\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise( Data , mu , std ):\n",
    "    noise = np.random.normal(mu, std, size = Data.shape)\n",
    "    Noisy_Data = Data + noise\n",
    "    return Noisy_Data \n",
    "\n",
    "#This function adds guassian noise to the data which is used to create a digital twin.\n",
    "\n",
    "#'Data' is the input data that the noise is going to be apply to , 'mu' is the mean , and 'std' is standard deviation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exp_form( X0 ,decay_constant , t ):\n",
    "\n",
    "    X = X0 * math.e**(-decay_constant*t) \n",
    "\n",
    "    return  X \n",
    "\n",
    "#This funtion calculates the the change of X as a function of time using the exponetial decay formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Data_Set( df , df_test ):\n",
    "\n",
    "    # Original_Half_Life and Test_Original_Half_Life are just an array of the original Half-Life in days before the Digital twin is created\n",
    "\n",
    "    Original_Half_Life = np.array( ( df['Days'] ))\n",
    "    \n",
    "    Test_Original_Half_Life =np.array( ( df_test['Days'] )) \n",
    "\n",
    "    #The two loops below create \n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    #input the number the times you want the training data to be replicated with a guassian noise (currently set to 1000) Total number of rows = 1000* (Oringinal amount of rows )\n",
    "\n",
    "    for i in range(1000): \n",
    "        \n",
    "        Noisey_Half_Life = gaussian_noise(Original_Half_Life , mu , std)        \n",
    "\n",
    "        Noisey_Decay = ( np.log(2) ) / Noisey_Half_Life\n",
    "\n",
    "        Noisey_Data = pd.DataFrame( {'Days' : Noisey_Half_Life , 'Decay_Constant' : Noisey_Decay } )\n",
    "\n",
    "        df = pd.concat([df, Noisey_Data] )\n",
    "\n",
    "    #The number the times you want the testing data to be replicated with a guassian noise (currently set to 1000). Total number of rows = 1000 * (Oringinal amount of rows )\n",
    "\n",
    "    for i in range(1000):  \n",
    "        Noisey_Test_Half_Life = gaussian_noise(Test_Original_Half_Life , mu , std)\n",
    "\n",
    "        Noisey_Test_Decay = ( np.log(2) ) / Noisey_Test_Half_Life\n",
    "\n",
    "        Noisey_Test_Data = pd.DataFrame( {'Days' : Noisey_Test_Half_Life , 'Decay_Constant' : Noisey_Test_Decay } )\n",
    "\n",
    "        df_test = pd.concat([df_test , Noisey_Test_Data])\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    df_test.reset_index(inplace= True, drop = True)\n",
    "\n",
    "    print('Complete Step #1 ')   \n",
    "\n",
    "    index_start=0\n",
    "\n",
    "    index_end= len(Original_Half_Life) \n",
    "\n",
    "    Decay_data = list(df['Decay_Constant'])\n",
    "\n",
    "    Test_Decay_data =list(df_test['Decay_Constant'])\n",
    "\n",
    "    #For each isotopes decay constant, model the decay as a funtion of time\n",
    "    # range(round(max(df['Days'])*10)) takes the largest half life in the data set, multiplys by 10 then rounds it to make sure its a whole number... that is the maximum amount of time the test is going to be runnning for increasing by increments of 5\n",
    "\n",
    "    #The for loop simulates the dacay of each element and appends it to df\n",
    "\n",
    "    for  t in range(0,round(max(df['Days'])*10),5):\n",
    "    \n",
    "        \n",
    "\n",
    "        Moving_Data=[ Exp_form ( N0 , decay_constant , t  ) for decay_constant in Decay_data]\n",
    "\n",
    "        Moving_Test_Data=[ Exp_form ( N0 , decay_constant , t  ) for decay_constant in Test_Decay_data]\n",
    "\n",
    "        \n",
    "        interval_data = pd.DataFrame({ str(t) : Moving_Data  })\n",
    "        test_interval_data = pd.DataFrame({ str(t) : Moving_Test_Data  })\n",
    "\n",
    "        \n",
    "\n",
    "        df = pd.concat([ df , interval_data ],axis=1 )\n",
    "        df_test = pd.concat([ df_test , test_interval_data ] ,axis=1)\n",
    "\n",
    "        index_start +=len( Original_Half_Life )\n",
    "        index_end+=len( Original_Half_Life )\n",
    "\n",
    "    print('Complete step #2')   \n",
    "\n",
    "    #Make the list of radioactive isotope names and replaces them with a list of numberical values corresponding to the name of the Isotopes        \n",
    "\n",
    "    \n",
    "    Numeric_Isotope_Identifications=[]\n",
    "    Test_Numeric_Isotope_Identifications=[]\n",
    "\n",
    " #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    for  i in range( int( len(df)/len(Original_Half_Life) ) ):\n",
    "\n",
    "        [Numeric_Isotope_Identifications.append(j) for j in range(len( Original_Half_Life ))]\n",
    "\n",
    "    for i in range ( int(len(df_test)/len(Test_Original_Half_Life) ) ):\n",
    "        [Test_Numeric_Isotope_Identifications.append(j) for j in range(len( Test_Original_Half_Life ))]\n",
    "\n",
    "\n",
    " #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "\n",
    "        \n",
    "    Numeric_Isotope_Identifications = pd.DataFrame({ 'Isotope' : Numeric_Isotope_Identifications } )\n",
    "    Test_Numeric_Isotope_Identifications = pd.DataFrame({ 'Isotope' : Test_Numeric_Isotope_Identifications } )\n",
    "   \n",
    "    \n",
    "    df = pd.concat( [df , Numeric_Isotope_Identifications] , axis=1 )\n",
    "    df_test = pd.concat( [df_test , Test_Numeric_Isotope_Identifications] , axis=1 )\n",
    "\n",
    "\n",
    "    return df , df_test , Isotope_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Data_Frame(df , df_test):\n",
    "\n",
    "    Row_list=[]\n",
    "    X_values = list(df.columns.values)\n",
    "\n",
    "    for index, rows in df.iterrows():\n",
    "        # Create list for the current row\n",
    "\n",
    "        plt.plot(X_values , list(df.iloc[index]) )\n",
    "\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training ( df , df_train ,Isotope_List ):\n",
    "\n",
    "    #Training uses a hidden markov model \n",
    "    my_feature_columns = []\n",
    "    for key in df.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    print(my_feature_columns)\n",
    "\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "                feature_columns=my_feature_columns,\n",
    "                # Two hidden layers of 128 and 64 nodes respectively. 256,128\n",
    "                hidden_units=[128,64],\n",
    "                # The model must choose between the number of Isotopes in 'Isotope_List' classes.\n",
    "                n_classes=len(Isotope_List))\n",
    "\n",
    "    clear_output()\n",
    "    \n",
    "    model.train(\n",
    "        input_fn=lambda: input_fn(df, df_train, training=True),\n",
    "        steps=6000)\n",
    "\n",
    "    clear_output()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Elle\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\Elle\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:86: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-0.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-0.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-0.meta\n",
      "INFO:tensorflow:45100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.7725654, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.7464\n",
      "INFO:tensorflow:loss = 1.6122301, step = 100 (57.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11046\n",
      "INFO:tensorflow:loss = 1.4986255, step = 200 (32.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.17757\n",
      "INFO:tensorflow:loss = 1.4261644, step = 300 (45.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64915\n",
      "INFO:tensorflow:loss = 1.3850951, step = 400 (37.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.18597\n",
      "INFO:tensorflow:loss = 1.3861054, step = 500 (45.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71067\n",
      "INFO:tensorflow:loss = 1.3290281, step = 600 (58.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.53887\n",
      "INFO:tensorflow:loss = 1.3219285, step = 700 (39.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.55407\n",
      "INFO:tensorflow:loss = 1.3075428, step = 800 (39.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.1675\n",
      "INFO:tensorflow:loss = 1.2438192, step = 900 (46.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99907\n",
      "INFO:tensorflow:loss = 1.2336497, step = 1000 (50.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87117\n",
      "INFO:tensorflow:loss = 1.2242129, step = 1100 (53.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.69331\n",
      "INFO:tensorflow:loss = 1.1526191, step = 1200 (37.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15946\n",
      "INFO:tensorflow:loss = 1.14782, step = 1300 (31.651 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1323...\n",
      "INFO:tensorflow:Saving checkpoints for 1323 into C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-1323.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-1323.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:C:\\Users\\Elle\\AppData\\Local\\Temp\\tmptuwjt100\\model.ckpt-1323.meta\n",
      "INFO:tensorflow:45100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1323...\n",
      "INFO:tensorflow:global_step/sec: 1.87161\n",
      "INFO:tensorflow:loss = 1.0685672, step = 1400 (53.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.07905\n",
      "INFO:tensorflow:loss = 1.1107659, step = 1500 (48.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.12816\n",
      "INFO:tensorflow:loss = 1.0624151, step = 1600 (46.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08646\n",
      "INFO:tensorflow:loss = 1.0473554, step = 1700 (47.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80497\n",
      "INFO:tensorflow:loss = 1.0053508, step = 1800 (55.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.67239\n",
      "INFO:tensorflow:loss = 0.9873986, step = 1900 (59.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30468\n",
      "INFO:tensorflow:loss = 1.0176458, step = 2000 (76.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54001\n",
      "INFO:tensorflow:loss = 1.0578995, step = 2100 (64.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77692\n",
      "INFO:tensorflow:loss = 0.96631134, step = 2200 (56.313 sec)\n"
     ]
    }
   ],
   "source": [
    "# Input the directory for the the Training and Testing CSV files #\n",
    "\n",
    "Training_filename=str(r'Desired Spreadsheet.csv')\n",
    "TestData_filename = str(r'Desired Spreadsheet_Test.csv')\n",
    "mu=0.0\n",
    "std = 0.01\n",
    "\n",
    "N0=1\n",
    "\n",
    "df , df_test , Isotope_List = Read_File( Training_filename,TestData_filename )\n",
    "\n",
    "\n",
    "df , df_test , Isotope_List = Create_Data_Set(df,df_test)\n",
    "\n",
    "df_train = df.pop('Isotope')\n",
    "df_test_eval = df_test.pop('Isotope')\n",
    "\n",
    "df.pop('Decay_Constant')\n",
    "df.pop('Days')\n",
    "\n",
    "\n",
    "print(\"Df shape : \" + str(df.shape) )\n",
    "\n",
    "print(\"Df_test shape : \" + str(df_test.shape) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "results={}\n",
    "\n",
    "\n",
    "\n",
    "model = training ( df , df_train ,Isotope_List  )\n",
    "\n",
    "eval_result = model.evaluate(\n",
    "    input_fn=lambda: input_fn(df_test, df_test_eval, training=False ))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "\n",
    "\n",
    "results.update({'Results accuracy' : eval_result['accuracy']})\n",
    "\n",
    "    \n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f5815527a0e5bfda1663ec258fb7dd857621fb624096f6e2455ba2ffaa3bb9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
